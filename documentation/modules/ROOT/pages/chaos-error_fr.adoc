:markup-in-source: verbatim,attributes,quotes
:CHE_URL: http://codeready-workspaces.%APPS_HOSTNAME_SUFFIX%
:USER_ID: %USER_ID%
:OPENSHIFT_PASSWORD: %OPENSHIFT_PASSWORD%
:OPENSHIFT_CONSOLE_URL: https://console-openshift-console.%APPS_HOSTNAME_SUFFIX%/topology/ns/chaos-engineering{USER_ID}/graph
:APPS_HOSTNAME_SUFFIX: %APPS_HOSTNAME_SUFFIX%
:KIALI_URL: https://kiali-istio-system.%APPS_HOSTNAME_SUFFIX%
:GRAFANA_URL: https://grafana-istio-system.%APPS_HOSTNAME_SUFFIX%
:GITOPS_URL: https://argocd-server-argocd.%APPS_HOSTNAME_SUFFIX%

= Expérience des chaos 2: Service non disponible

_10 MINUTES D'ENTRAÎNEMENT_

Auparavant, vous avez vu l'ampleur de l'impact sur l'application lorsqu'un petit problème de latence du réseau se produit sur un service non critique.
Voyons comment l'application se comportera lorsque ce même service sera indisponible. Pour cette deuxième expérience, nous allons tester l'hypothèse suivante:

_**L'indisponibilité d'un service de « remise » ne doit PAS avoir d'incidence sur l'objectif de niveau de service (SLO) du service de voyage**_

==  Définir l'état stable

Comme dans le laboratoire précédent, nous garderons le même état stable

**99% des demandes sont satisfaites et servies dans les 50 ms**

image::grafana-service-overview-configured-2.png[Grafana - Service Overview Configured,700]

Nous pourrons voir comment un autre type de défaillance du même service pourrait avoir un impact sur le comportement de notre application.

==  Exécutez l'expérience Chaos

Dans le {KIALI_URL}[Kiali Console^, role='params-link'], de la vue **'Graph'**, `*clic droit sur le service 'discounts' et sélectionnez 'Details'*`

image::kiali-right-click-service.png[Kiali - Right Click Service,400]

Vous serez redirigé vers la page détails du service.

`*Cliquez sur les 'Actions' 'Fault Injection'*`

image::kiali-add-fault-injection.png[Kiali - Add Fault Injection,900]

`*Add HTTP Abort by entering the following settings:*`

.HTTP Abort Settings
[%header,cols=3*]
|===
|Parameter
|Value
|Description

|Add HTTP Delay 
|**Disabled**
|

|Add HTTP Abort 
|**Enabled**
|

|Abort Percentage
|**10**
|

|HTTP Status Code
|**503**
|

|===

image::kiali-configure-error.png[Kiali - Configure Error,300]

`*Cliquez sur le bouton « Mise à jour »*`.

**10% du trafic du service 'discounts' échoue avec un code HTTP 503**. Voyons maintenant l'impact de l'application.

==  Analyser le résultat du chaos

Dans le {GRAFANA_URL}[Chaos Engineering Dashboard], vous pouvez voir le résultat de l'expérience de chaos.

image::grafana-error-fault-overview.png[Grafana - Error Fault Overview,900]

**Tous les services, à l'exception du service 'discounts', fonctionnent très bien sans erreurs (100% de succès)**.

Vous pouvez augmenter le pourcentage d'injection d'erreur jusqu'à ce que le service de « décomptes » soit complètement indisponible.

Dans le {KIALI_URL}[Kiali Console^, role='params-link'], `*mettre à jour la stratégie HTTP Abort du service 'discounts' comme suit:*`

`*Ajouter HTTP Abort en entrant les paramètres suivants:*`

.HTTP Abort Settings
[%header,cols=3*]
|===
|Parameter
|Value
|Description

|Add HTTP Delay 
|Disabled
|

|Add HTTP Abort 
|Enabled
|

|Abort Percentage
|**100**
|

|HTTP Status Code
|503
|

|===

image::grafana-error-fault-overview-2.png[Grafana - Error Fault Overview,900]

Contrairement au résultat de l'expérience de latence, vous indiquez que l'application est résiliente lorsque le service "discounts" est complètement indisponible (indisponible).
Donc votre hypothèse est validée :

_**Les services de 'remises' non disponibles N'ONT PAS d'incidence sur l'objectif de niveau de service (SLO) du service de voyage**_

== Rollback de l'expérience chaos

Dans {GITOPS_URL}[Argo CD^, role='params-link'], `*cliquez sur 'Sync > Synchronize '*`.

image::argocd-rollback-sync.png[Argo CD - Sync Application, 900]

Enfin, dans le {GRAFANA_URL}[Chaos Engineering Dashboard], ` *veuillez vérifier que l'application est de retour dans l'état stable.

image::grafana-steady-state.png[Grafana - Steady State,700]
